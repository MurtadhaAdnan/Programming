# ุฏูุงู PyTorch ุญุณุจ ูุณุชูู ุงูุฎุจุฑุฉ

## `ุงูููุฏูุฉ`
**PyTorch** ูู ุฃููู ููุชุจุงุช ุชุนูู ุงูุขูุฉ ูุงูุชุนูู ุงูุนููู:

- โ ุจูุงุก ููุงุฐุฌ ุงูุดุจูุงุช ุงูุนุตุจูุฉ
- โ ุญุณุงุจ ุชููุงุฆู ููุชุฏุฑุฌุงุช (Autograd)
- โ ุฏุนู ูุงูู ูู GPU/TPU

## `ุงููุฒุงูุง ุงูุฃุณุงุณูุฉ`

| ุงูููุฒุฉ | ุงูุดุฑุญ |
|--------|-------|
| โก ุฃุฏุงุก ุนุงูู | ุชุณุฑูุน ุงูุนูููุงุช ุจุงุณุชุฎุฏุงู GPU |
| ๐ง ูุฑููุฉ ุนุงููุฉ | ููุงุฐุฌ ุฏููุงููููุฉ ุจุงุณุชุฎุฏุงู Dynamic Computation Graph |
| ๐ ุชูุงูู ูุน Python | ุชูุงูู ุณูุณ ูุน ููุชุจุงุช Python ุงูุนูููุฉ |

---
<br><br><br>

## `ุงููุณุชูู ุงููุจุชุฏุฆ`

| ุงูุฏุงูุฉ | ุงููุตู | ูุซุงู | ุงููุชูุฌุฉ |
|--------|-------|------|---------|
| `torch.tensor(data)` | ุฅูุดุงุก ุชูุณูุฑ | `torch.tensor([1, 2, 3])` | ุชูุณูุฑ [1, 2, 3] |
| `torch.zeros(size)` | ุชูุณูุฑ ููููุก ุจุฃุตูุงุฑ | `torch.zeros(2, 3)` | ุชูุณูุฑ 2x3 ุจุฃุตูุงุฑ |
| `torch.ones(size)` | ุชูุณูุฑ ููููุก ุจูุงุญุฏุงุช | `torch.ones(2)` | ุชูุณูุฑ [1, 1] |
| `torch.rand(size)` | ุชูุณูุฑ ุจููู ุนุดูุงุฆูุฉ | `torch.rand(2, 2)` | ุชูุณูุฑ 2x2 ุจููู ุจูู 0 ู1 |
| `tensor.shape` | ุดูู ุงูุชูุณูุฑ | `x.shape` | ุงูุฃุจุนุงุฏ (2, 3) |
| `tensor.dtype` | ููุน ุจูุงูุงุช ุงูุชูุณูุฑ | `x.dtype` | torch.float32 |
| `tensor.to(device)` | ููู ุงูุชูุณูุฑ ูุฌูุงุฒ | `x.to('cuda')` | ุชูุณูุฑ ุนูู GPU |
| `torch.add(x, y)` | ุฌูุน ุชูุณูุฑุงุช | `torch.add(x, y)` | ูุงุชุฌ ุฌูุน x ู y |
| `torch.mm(x, y)` | ุถุฑุจ ูุตูููุงุช | `torch.mm(x, y)` | ูุชูุฌุฉ ุงูุถุฑุจ |
| `torch.sum(x)` | ูุฌููุน ุงูุชูุณูุฑ | `torch.sum(x)` | ุงููุฌููุน ุงูููู |

---
<br><br><br>

## `ุงููุณุชูู ุงููุชูุณุท`

| ุงูุฏุงูุฉ | ุงููุตู | ูุซุงู | ุงููุชูุฌุฉ |
|--------|-------|------|---------|
| `torch.nn.Linear(in, out)` | ุทุจูุฉ ุฎุทูุฉ | `nn.Linear(10, 5)` | ุทุจูุฉ 10 โ 5 |
| `torch.nn.Conv2d(in, out, k)` | ุทุจูุฉ ุชูุงููููุฉ | `nn.Conv2d(3, 16, 3)` | ุทุจูุฉ ุชูุงููู 3x3 |
| `torch.nn.ReLU()` | ุฏุงูุฉ ุชูุนูู ReLU | `nn.ReLU()` | ุฏุงูุฉ ุงูุชูุนูู |
| `torch.optim.SGD()` | ูุญุณู SGD | `optim.SGD(model.parameters(), lr=0.01)` | ูุงุฆู ุงููุญุณู |
| `nn.CrossEntropyLoss()` | ุฏุงูุฉ ุฎุณุงุฑุฉ | `nn.CrossEntropyLoss()` | ุฏุงูุฉ ุงูุฎุณุงุฑุฉ |
| `model.eval()` | ูุถุน ุงูุชูููู | `model.eval()` | ุฅููุงู Dropout/BatchNorm |
| `torch.save(model, path)` | ุญูุธ ุงููููุฐุฌ | `torch.save(model, 'model.pth')` | ููู ุงููููุฐุฌ |
| `torch.load(path)` | ุชุญููู ุงููููุฐุฌ | `torch.load('model.pth')` | ุงููููุฐุฌ ุงููุญูู |
| `DataLoader(dataset, batch)` | ุชุญููู ุงูุจูุงูุงุช | `DataLoader(ds, batch_size=32)` | ูุญูู ุงูุจูุงูุงุช |
| `torchvision.transforms` | ุชุญูููุงุช ุงูุตูุฑ | `transforms.Compose([...])` | ุชุญูููุงุช ุงูุตูุฑ |

---
<br><br><br>

## `ุงููุณุชูู ุงููุชูุฏู`

| ุงูุฏุงูุฉ | ุงููุตู | ูุซุงู | ุงููุชูุฌุฉ |
|--------|-------|------|---------|
| `torch.autograd.grad()` | ุญุณุงุจ ุงูุชุฏุฑุฌุงุช | `torch.autograd.grad(output, input)` | ุชุฏุฑุฌุงุช ุงูุฅุฎุฑุงุฌ |
| `@torch.jit.script` | ุชุญููู ุงููููุฐุฌ ูู TorchScript | `@torch.jit.script def foo(x):` | ูููุฐุฌ ูุญุณู |
| `torch.distributed` | ุชุฏุฑูุจ ููุฒุน | `torch.distributed.init_process_group()` | ุฅุนุฏุงุฏ ุงูุชุฏุฑูุจ ุงูููุฒุน |
| `torch.nn.Parameter()` | ูุนููุฉ ุงููููุฐุฌ | `nn.Parameter(torch.rand(10))` | ูุนููุฉ ูุงุจูุฉ ููุชุนูู |
| `torch.nn.utils.clip_grad_` | ูุต ุงูุชุฏุฑุฌุงุช | `clip_grad_norm_(model.parameters(), 1.0)` | ุชุฏุฑุฌุงุช ููุตูุตุฉ |
| `torch.onnx.export()` | ุชุตุฏูุฑ ูู ONNX | `torch.onnx.export(model, ...)` | ูููุฐุฌ ONNX |
| `torch.jit.trace()` | ุชุชุจุน ุงููููุฐุฌ | `torch.jit.trace(model, example_input)` | ูููุฐุฌ ูุชุชุจุน |
| `torch.nn.DataParallel` | ุชุฏุฑูุจ ูุชูุงุฒู | `DataParallel(model)` | ูููุฐุฌ ูุชูุงุฒู |
| `torch.cuda.amp` | ุชุฏุฑูุจ ูุฎุชูุท ุงูุฏูุฉ | `autocast(enabled=True)` | ุชุฏุฑูุจ ุฃุณุฑุน |
| `torch.nn.functional` | ุฏูุงู ุงูุดุจูุงุช | `F.interpolate(x, scale_factor=2)` | ุชุบููุฑ ุญุฌู ุงูุตูุฑ |

---
<br><br><br>

## `ูุณุชูู ุงูุฎุจูุฑ`

| ุงูุฏุงูุฉ | ุงููุตู | ูุซุงู | ุงููุชูุฌุฉ |
|--------|-------|------|---------|
| `torch.autograd.Function` | ุฏุงูุฉ ูุฎุตุตุฉ | `class MyFunc(Function): ...` | ุนูููุฉ ูุฎุตุตุฉ |
| `torch.nn.Module` | ุจูุงุก ูููุฐุฌ ูุฎุตุต | `class MyModel(nn.Module): ...` | ูููุฐุฌ ูุฎุตุต |
| `torch._C` | ูุงุฌูุฉ C++ | `torch._C._jit_pass_constant_propagation` | ูุตูู ููุฎูุถ ุงููุณุชูู |
| `torch.utils.benchmark` | ููุงุณ ุงูุฃุฏุงุก | `Timer(stmt='x + y', ...)` | ููุงุณ ุฒูู ุงูุชูููุฐ |
| `torch.profiler` | ุชุญููู ุงูุฃุฏุงุก | `torch.profiler.profile(...)` | ุชุญููู ุงูุฃุฏุงุก |
| `torch.utils.tensorboard` | ุชุตูุฑ ุงูุชุฏุฑูุจ | `SummaryWriter()` | ุชุณุฌูู ูุชุงุฆุฌ ุงูุชุฏุฑูุจ |
| `torch.distributions` | ุงูุชูุฒูุนุงุช ุงูุงุญุชูุงููุฉ | `distributions.Normal(0, 1)` | ุชูุฒูุน ุงุญุชูุงูู |
| `torch.sparse` | ุชูุณูุฑุงุช ูุชูุงุซุฑุฉ | `torch.sparse_coo_tensor(...)` | ุชูุณูุฑุงุช ูุชูุงุซุฑุฉ |
| `torch.jit.script_if_tracing` | ุชุญุณูู ุงูุจุฑูุฌุฉ | `@script_if_tracing def foo(x):` | ุชุญุณูู ุงูุจุฑูุฌุฉ |
| `torch.overrides` | ุชุนุฏูู ุงูุณููู | `@overrides.handle_torch_function` | ุชุนุฏูู ุณููู PyTorch |